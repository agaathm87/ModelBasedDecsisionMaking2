{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcad92c",
   "metadata": {},
   "source": [
    "# Granovetter Threshold Model — Targeting for Maximum Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e289af",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d052ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "\n",
    "print(\"Packages loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093c2af",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe0894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=300, k_avg=6, B=5, ENSEMBLES=10, RUNS_PER_SETTING=15\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "N = 300 # Number of nodes\n",
    "k_avg = 6 # Average degree we aim for\n",
    "B = 5 # Number of initial adopters\n",
    "ENSEMBLES = 10 # Number of ensemble simulations to run\n",
    "RUNS_PER_SETTING = 15 # Number of simulation runs for each threshold setting\n",
    "\n",
    "# Threshold mode, defines how the threshold is set for each node\n",
    "THRESHOLD_MODE = 'beta'   # 'uniform', 'beta', 'constant', 'normal'\n",
    "PHI_MEAN = 0.30\n",
    "PHI_STD = 0.10\n",
    "\n",
    "# Maximum number of steps in each simulation run\n",
    "MAX_STEPS = 200\n",
    "# Number of steps to run the greedy algorithm for\n",
    "GREEDY_R = 5\n",
    "\n",
    "print(f\"N={N}, k_avg={k_avg}, B={B}, ENSEMBLES={ENSEMBLES}, RUNS_PER_SETTING={RUNS_PER_SETTING}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e25e7",
   "metadata": {},
   "source": [
    "## 3. Network Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5318e168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ER': (300, 858), 'WS': (300, 900), 'BA': (300, 891)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This function builds three different types of networks: Erdős-Rényi (ER), Watts-Strogatz (WS), and Barabási-Albert (BA)\n",
    "# Each network is generated with a specified number of nodes (N) and average degree (k_avg)\n",
    "# The seed_base parameter is used to ensure different random networks are generated each time the function is called\n",
    "def build_networks(N, k_avg, seed_base=0):\n",
    "    p_er = k_avg / (N - 1)\n",
    "    G_er = nx.erdos_renyi_graph(N, p_er, seed=seed_base + 1)\n",
    "\n",
    "    k_ws = max(2, int(round(k_avg)))\n",
    "    if k_ws % 2 == 1:\n",
    "        k_ws += 1\n",
    "    p_ws = 0.1\n",
    "    G_ws = nx.watts_strogatz_graph(N, k_ws, p_ws, seed=seed_base + 2)\n",
    "\n",
    "    m_ba = max(1, int(k_avg // 2))\n",
    "    G_ba = nx.barabasi_albert_graph(N, m_ba, seed=seed_base + 3)\n",
    "\n",
    "    return {'ER': G_er, 'WS': G_ws, 'BA': G_ba}\n",
    "\n",
    "graphs = build_networks(N, k_avg, seed_base=RANDOM_SEED)\n",
    "{name: (G.number_of_nodes(), G.number_of_edges()) for name, G in graphs.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bf396",
   "metadata": {},
   "source": [
    "## 4. Threshold Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bf8e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ER threshold mean: 0.276\n",
      "WS threshold mean: 0.298\n",
      "BA threshold mean: 0.28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This function draws threshold values for each node in the graph G\n",
    "# The threshold mode determines how the threshold values are generated\n",
    "# Each node samples a threshold value from a specified distribution (defined by mode)\n",
    "# The phi_mean and phi_std parameters are used to control the mean and standard deviation of the normal distribution\n",
    "def draw_thresholds(G, mode='uniform', phi_mean=0.3, phi_std=0.1):\n",
    "    if mode == 'uniform':\n",
    "        return {n: np.random.uniform(0, 1) for n in G}\n",
    "    if mode == 'beta':\n",
    "        a, b = 2, 5\n",
    "        return {n: np.random.beta(a, b) for n in G}\n",
    "    if mode == 'constant':\n",
    "        return {n: float(phi_mean) for n in G}\n",
    "    if mode == 'normal':\n",
    "        vals = np.clip(np.random.normal(phi_mean, phi_std, len(G)), 0, 1)\n",
    "        return {n: float(vals[i]) for i, n in enumerate(G)}\n",
    "    raise ValueError(f\"Unknown threshold mode: {mode}\")\n",
    "\n",
    "# This loop iterates over each graph in the graphs dictionary\n",
    "# For each graph, it draws threshold values using the draw_thresholds function\n",
    "# It then calculates the mean of these threshold values and prints it\n",
    "for name, G in graphs.items():\n",
    "    th = draw_thresholds(G, mode=THRESHOLD_MODE, phi_mean=PHI_MEAN, phi_std=PHI_STD)\n",
    "    arr = np.array(list(th.values()))\n",
    "    print(name, \"threshold mean:\", round(arr.mean(), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d426fc",
   "metadata": {},
   "source": [
    "## 5. Threshold Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f0b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function simulates the threshold dynamics on a graph G\n",
    "# The function takes as input the graph G, a list of seed nodes (seeds), a dictionary of threshold values (thresholds), and the maximum number of steps (max_steps)\n",
    "# The function returns a dictionary of adopted nodes (adopted) and a numpy array of the fraction of adopted nodes over time (history)\n",
    "def threshold_dynamics(G, seeds, thresholds, max_steps=100):\n",
    "    adopted = {n: 0 for n in G}\n",
    "    for s in seeds:\n",
    "        adopted[s] = 1 # initially, all seed nodes are adopted\n",
    "\n",
    "    history = [sum(adopted.values()) / len(G)] #the history will store the fraction of adopted nodes over time, initially it is the fraction of adopted seed nodes\n",
    "\n",
    "    for _ in range(max_steps): # iterate max_steps times\n",
    "        new_adopted = adopted.copy()\n",
    "        changed = False\n",
    "        for i in G: # iterate over all nodes i in the graph G\n",
    "            if adopted[i] == 0: # if node i is not adopted yet\n",
    "                neigh = list(G.neighbors(i))\n",
    "                if not neigh: # if node i has no neighbors, skip it\n",
    "                    continue\n",
    "                frac = sum(adopted[j] for j in neigh) / len(neigh) # calculate the fraction of adopted neighbors of node i\n",
    "                if frac >= thresholds[i]: # if the fraction of adopted neighbors is greater than or equal to the threshold of node i\n",
    "                    new_adopted[i] = 1 # adopt node i\n",
    "                    changed = True\n",
    "        #-- end of one iteration\n",
    "\n",
    "        # update the adopted nodes after checking all nodes\n",
    "        adopted = new_adopted\n",
    "        history.append(sum(adopted.values()) / len(G)) #add the total adopted this timestep to the history\n",
    "        if not changed:\n",
    "            break # if no node is adopted in this iteration, break the loop (no more adoptions so we can stop)\n",
    "\n",
    "    return adopted, np.array(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147352f1",
   "metadata": {},
   "source": [
    "## 6. Measurement Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a5bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def final_adoption_fraction(adopted):\n",
    "    return sum(adopted.values()) / len(adopted)\n",
    "\n",
    "# function to calculate the time to reach a target fraction of adopted nodes\n",
    "def time_to_fraction(history, target=0.5):\n",
    "    idx = np.where(history >= target)[0]\n",
    "    return float(idx[0]) if len(idx) else np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25f46c",
   "metadata": {},
   "source": [
    "## 7. Seeding Strategies — Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fbe340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_seeds(G, B):\n",
    "    return random.sample(list(G.nodes()), B)\n",
    "\n",
    "def high_degree_seeds(G, B):\n",
    "    \"\"\"\n",
    "    Select the top-B nodes with the highest degree in graph G.\n",
    "    \"\"\"\n",
    "    # Get all (node, degree) pairs\n",
    "    degree_list = list(G.degree())\n",
    "\n",
    "    # Sort nodes by degree in descending order\n",
    "    sorted_by_degree = sorted(degree_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Take the top-B entries\n",
    "    top_B = sorted_by_degree[:B]\n",
    "\n",
    "    # Extract only the node IDs\n",
    "    result = []\n",
    "    for n, d in top_B:\n",
    "        result.append(n)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#This code below does the same as for degree. It uses a list comprehension and a lambda function.\n",
    "# The lambda function takes a tuple x = (n, b) and returns the second element (b), which is the betweenness centrality of node n.]\n",
    "# sorted(bc.items(), key=lambda x: x[1], reverse=True) sorts the items of the dictionary bc.items() by the value of the betweenness centrality (x[1]) in descending order. (Highest first)\n",
    "# [:B] takes the first B entries from the sorted list, which are the nodes with the highest betweenness centrality.\n",
    "def betweenness_seeds(G, B):\n",
    "    bc = nx.betweenness_centrality(G) #returns a dictionary that maps each node to its betweenness centrality. {n_1: bc(n_1), n_2: bc(n_2), ...}\n",
    "    return [n for n, _ in sorted(bc.items(), key=lambda x: x[1], reverse=True)[:B]]\n",
    "\n",
    "\n",
    "# This function seeds the network with B nodes with the highest core number, the core number is the number of nodes that are connected to all its neighbors\n",
    "# For a given graph G, the core number of a node v is the largest integer k such that v belongs to the k-core of G.\n",
    "# In other words:\n",
    "# \t•\tIt tells you how deeply embedded a node is within the dense core structure of the network.\n",
    "# \t•\tA higher core number means the node is part of a more cohesive and connected region of the graph.\n",
    "def kcore_seeds(G, B):\n",
    "    core = nx.core_number(G) #core_number is a dictionary that maps each node to its core number. \n",
    "    return [n for n, _ in sorted(core.items(), key=lambda x: x[1], reverse=True)[:B]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e1535",
   "metadata": {},
   "source": [
    "## 8. Spread Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a524be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function estimates the spread of the threshold dynamics on graph G\n",
    "# It runs the threshold dynamics R times with different random seeds and thresholds\n",
    "# and returns the average final adoption fraction\n",
    "def estimate_spread(G, seeds, thresholds, R=5, max_steps=100):\n",
    "    results = []\n",
    "    for _ in range(R):\n",
    "        adopted, _ = threshold_dynamics(G, seeds, thresholds, max_steps=max_steps)\n",
    "        results.append(final_adoption_fraction(adopted))\n",
    "    return float(np.mean(results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890f29a",
   "metadata": {},
   "source": [
    "## 9. Greedy Marginal Gain (CELF-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b96ba475",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_celf(G, B, thresholds, R=5, max_steps=100, verbose=False):\n",
    "    \"\"\"\n",
    "    CELF-like lazy greedy influence maximization.\n",
    "    Uses submodularity to reduce marginal gain recomputations.\n",
    "    Returns: list of selected seed nodes (length B)\n",
    "    \"\"\"\n",
    "    base_current = estimate_spread(G, [], thresholds, R=1, max_steps=max_steps)\n",
    "\n",
    "    PQ = [] # priority queue, store the seed nodes with their gains (their impact on final adoption when they are added to the seed set)\n",
    "    for v in G:\n",
    "        gain_v = estimate_spread(G, [v], thresholds, R=R, max_steps=max_steps) - base_current\n",
    "        PQ.append({'v': v, 'gain': gain_v, 'updated_at': -1})\n",
    "    PQ.sort(key=lambda d: d['gain'], reverse=True)\n",
    "\n",
    "    S = [] # selected seed nodes\n",
    "    k = 0 # current iteration number\n",
    "    while len(S) < B and PQ: # while we have not selected B seed nodes and the priority queue is not empty\n",
    "        top = PQ.pop(0) # pop the node with the highest gain, first in PQ\n",
    "        v = top['v']\n",
    "        if top['updated_at'] == k: # if the node v is  updated in the current iteration\n",
    "            S.append(v) # add the node v to the seed set\n",
    "            k += 1 # update the current iteration number\n",
    "            base_current = estimate_spread(G, S, thresholds, R=1, max_steps=max_steps) # update the current spread of the threshold dynamics\n",
    "            if verbose:\n",
    "                print(f\"Accepted {v} with gain ~ {top['gain']:.4f}. |S|={len(S)}\")\n",
    "        else: # if the node v is not updated in the current iteration\n",
    "            gain_true = estimate_spread(G, S + [v], thresholds, R=R, max_steps=max_steps) - base_current # compute the true gain of adding v to the seed set\n",
    "            top['gain'] = gain_true\n",
    "            top['updated_at'] = k\n",
    "            PQ.append(top) # add the node v to the priority queue with its updated gain\n",
    "            PQ.sort(key=lambda d: d['gain'], reverse=True) # sort the priority queue by the gain in descending order\n",
    "\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b3ddb",
   "metadata": {},
   "source": [
    "## 10. Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7977c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 16) (2411999533.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 16\u001b[1;36m\u001b[0m\n\u001b[1;33m    K-core': lambda: kcore_seeds(G, B),\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_experiments(N, k_avg, ensembles=5, runs_per_setting=10, threshold_mode='beta',\n",
    "                    phi_mean=0.3, phi_std=0.1, B=5, max_steps=200, greedy_R=5):\n",
    "    import numpy as _np\n",
    "    import pandas as _pd\n",
    "    from time import time as _time\n",
    "    results = []\n",
    "    t0 = _time()\n",
    "    for e in range(ensembles): # for each ensemble\n",
    "        graphs = build_networks(N, k_avg, seed_base=RANDOM_SEED + e * 10) # build the networks\n",
    "        for name, G in graphs.items(): # for each network\n",
    "            thresholds = draw_thresholds(G, mode=threshold_mode, phi_mean=phi_mean, phi_std=phi_std) # draw the thresholds for each node from the distribution specified by threshold_mode\n",
    "\n",
    "            strategies = { #dictionary of seed selection strategies, the value is a (lamba) function that returns the seed set for the current strategy\n",
    "                'Random': lambda: random_seeds(G, B),\n",
    "                'Degree': lambda: high_degree_seeds(G, B),\n",
    "                K-core': lambda: kcore_seeds(G, B),\n",
    "                'Betweenness': lambda: betweenness_seeds(G, B),\n",
    "                Greedy': lambda: greedy_celf(G, B, thresholds, R=greedy_R, max_steps=max_steps, verbose=False)\n",
    "            }\n",
    "\n",
    "            for strat, seed_fn in strategies.items(): # for each seed selection strategy\n",
    "                seeds = seed_fn() # get the seed set for the current strategy\n",
    "                final_sizes, t50_list = [], []\n",
    "                for _ in range(runs_per_setting):\n",
    "                    adopted, history = threshold_dynamics(G, seeds, thresholds, max_steps=max_steps)\n",
    "                    final_sizes.append(final_adoption_fraction(adopted))\n",
    "                    t50_list.append(time_to_fraction(history, target=0.5))\n",
    "                results.append({\n",
    "                    'Ensemble': e,\n",
    "                    'Network': name,\n",
    "                    'Strategy': strat,\n",
    "                    'FinalAdoption': float(_np.mean(final_sizes)),\n",
    "                    'CascadeProb': float(_np.mean(_np.array(final_sizes) >= 0.5)),\n",
    "                    'Time50': float(_np.nanmean(t50_list)),\n",
    "                    'Efficiency': float(_np.mean(final_sizes) / B),\n",
    "                    'Seeds': seeds\n",
    "                })\n",
    "    t1 = _time()\n",
    "    print(f\"Completed {ensembles} ensembles x 3 networks x 5 strategies in {t1 - t0:.1f}s\")\n",
    "    return _pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a93fa7",
   "metadata": {},
   "source": [
    "## 11. Run the full experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce43070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_results = run_experiments(\n",
    "    N=N,\n",
    "    k_avg=k_avg,\n",
    "    ensembles=ENSEMBLES,\n",
    "    runs_per_setting=RUNS_PER_SETTING,\n",
    "    threshold_mode=THRESHOLD_MODE,\n",
    "    phi_mean=PHI_MEAN,\n",
    "    phi_std=PHI_STD,\n",
    "    B=B,\n",
    "    max_steps=MAX_STEPS,\n",
    "    greedy_R=GREEDY_R\n",
    ")\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be43553b",
   "metadata": {},
   "source": [
    "## 12. Save results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af13721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = \"/mnt/data/granovetter_experiment_results.csv\"\n",
    "df_results.to_csv(csv_path, index=False)\n",
    "print(\"Saved:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30ea21",
   "metadata": {},
   "source": [
    "## 13. Summaries and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot_final = df_results.pivot_table(index='Strategy', columns='Network', values='FinalAdoption', aggfunc='mean')\n",
    "pivot_cascade = df_results.pivot_table(index='Strategy', columns='Network', values='CascadeProb', aggfunc='mean')\n",
    "pivot_eff = df_results.pivot_table(index='Strategy', columns='Network', values='Efficiency', aggfunc='mean')\n",
    "\n",
    "print(\"Final adoption (mean):\")\n",
    "display(pivot_final)\n",
    "print(\"\\nCascade probability (mean):\")\n",
    "display(pivot_cascade)\n",
    "print(\"\\nEfficiency (mean):\")\n",
    "display(pivot_eff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1f8f7",
   "metadata": {},
   "source": [
    "## 14. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e74adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate charts per metric, no seaborn and no explicit colors\n",
    "metrics = ['FinalAdoption', 'CascadeProb', 'Efficiency']\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    df_results.boxplot(column=metric, by='Strategy', grid=False)\n",
    "    plt.title(metric)\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Strategy\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc47ef",
   "metadata": {},
   "source": [
    "\n",
    "## 15. Discussion\n",
    "- Cluster-focused and threshold-aware strategies (k-core, betweenness) often outperform degree targeting at intermediate thresholds by leveraging local reinforcement.\n",
    "- Bridge targeting can unlock cascades across communities in modular graphs.\n",
    "- Greedy (CELF-like) tends to yield the best performance for small to medium seed budgets, at higher computational cost, but the lazy updates keep it tractable.\n",
    "- Adjust `THRESHOLD_MODE`, `B`, `ENSEMBLES`, and `RUNS_PER_SETTING` to trade off runtime versus statistical stability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
